{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cse465-blurr.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NddpvyIHVNcH"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7bd3f332def346afac7dacba83e807c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ebfdf3c4e328487baa8f5469cdf94f1f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1b661d8b010348fa936e58c097071fe2",
              "IPY_MODEL_3ee0f74fe20b4bfba0290f4f73dd52a2"
            ]
          }
        },
        "ebfdf3c4e328487baa8f5469cdf94f1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b661d8b010348fa936e58c097071fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e7d8eb52bf524053b0f59af4a213bab0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_050e967ec01a41bfbce532291a101e1e"
          }
        },
        "3ee0f74fe20b4bfba0290f4f73dd52a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b0d71865fdec41bcb92bbc3d2fcf71f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:00&lt;00:00, 2.22MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4bcf09fe7b704f7cb2118217567c3c26"
          }
        },
        "e7d8eb52bf524053b0f59af4a213bab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "050e967ec01a41bfbce532291a101e1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b0d71865fdec41bcb92bbc3d2fcf71f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4bcf09fe7b704f7cb2118217567c3c26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c13cda9c5bc44596871256f6d29c8d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d2ea122559d949e8aae0e671f940e588",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d40151364c784855981fd3fbb343b2d9",
              "IPY_MODEL_5f199d95e4514499aed60139c4394b43"
            ]
          }
        },
        "d2ea122559d949e8aae0e671f940e588": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d40151364c784855981fd3fbb343b2d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0287b5b80563471a9b1e2e8cf4807b76",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab1e517e21af413f8507eaf73d426a0e"
          }
        },
        "5f199d95e4514499aed60139c4394b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c4511a0d19154697b971a73963bbdad6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 3.17MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a795c8acac44d6aadcfefee7a4289ea"
          }
        },
        "0287b5b80563471a9b1e2e8cf4807b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab1e517e21af413f8507eaf73d426a0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4511a0d19154697b971a73963bbdad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a795c8acac44d6aadcfefee7a4289ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "208ade4e39bb4790a74eba1375764392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_589963d68bd84033b949b08060d55ca9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_13da4546227042cbbee7cb6152cbec9d",
              "IPY_MODEL_cab3e8400293482e9685e741a5728d3d"
            ]
          }
        },
        "589963d68bd84033b949b08060d55ca9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13da4546227042cbbee7cb6152cbec9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7e3691a5635a48fd96ea4c13711d072f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1300,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1300,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2576b722c3ff4adb955164776729885f"
          }
        },
        "cab3e8400293482e9685e741a5728d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_14d992d0e9344517bfdb47840d6f724c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.30k/1.30k [00:00&lt;00:00, 5.10kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_17b3369ac4d9459a9e4a52a006bb5b62"
          }
        },
        "7e3691a5635a48fd96ea4c13711d072f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2576b722c3ff4adb955164776729885f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14d992d0e9344517bfdb47840d6f724c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "17b3369ac4d9459a9e4a52a006bb5b62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eab6795ac63c45a089404b51782d8acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ce4afd8ce922450e949daa7e86023682",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d0d696a3fd29495d9df225cbde64ed86",
              "IPY_MODEL_ea3bf49063b44f119efd04ae4f0eeb8d"
            ]
          }
        },
        "ce4afd8ce922450e949daa7e86023682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0d696a3fd29495d9df225cbde64ed86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8a25395499094b45b7bc66b92406dad7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1625270765,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1625270765,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e08c3058d27f48e29f2b71a6023c3619"
          }
        },
        "ea3bf49063b44f119efd04ae4f0eeb8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a1b0743a53274c8ea9e02bbdce162542",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.63G/1.63G [00:36&lt;00:00, 44.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe4406ba28b7402c9a42576abc62865a"
          }
        },
        "8a25395499094b45b7bc66b92406dad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e08c3058d27f48e29f2b71a6023c3619": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1b0743a53274c8ea9e02bbdce162542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe4406ba28b7402c9a42576abc62865a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGcKW5SCHVqs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "02d2d96c-2fe5-487d-e4ac-d233003aa569"
      },
      "source": [
        "# only run this cell if you are in collab\n",
        "!pip install ohmeow-blurr\n",
        "!pip install nlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ohmeow-blurr\n",
            "  Downloading https://files.pythonhosted.org/packages/26/e7/df8185592c29ac769e4558f4e4cd36454d2121f914d4dfb7e96aa36eb826/ohmeow_blurr-0.0.5-py3-none-any.whl\n",
            "Collecting fastcore\n",
            "  Downloading https://files.pythonhosted.org/packages/dd/f3/8cd2e1ed981b0ddbe4d56e5d44f52c9e56d27ac7d53c30abb534d10c82c2/fastcore-0.1.17-py3-none-any.whl\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from ohmeow-blurr) (4.10.1)\n",
            "Collecting fastai2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/4f/0f61bb0d376eb47c20430639bac4946ca0cffcd7e693fb86698656324f2d/fastai2-0.0.17-py3-none-any.whl (190kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 6.4MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\u001b[K     |████████████████████████████████| 675kB 8.5MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastcore->ohmeow-blurr) (1.18.4)\n",
            "Requirement already satisfied: dataclasses>='0.7'; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastcore->ohmeow-blurr) (0.7)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->ohmeow-blurr) (4.5.3)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->ohmeow-blurr) (4.3.3)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->ohmeow-blurr) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->ohmeow-blurr) (5.3.4)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (0.6.0+cu101)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (3.2.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (7.0.0)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (1.5.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (3.13)\n",
            "Requirement already satisfied: fastprogress>=0.1.22 in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (0.2.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (1.0.4)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (2.2.4)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 17.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers->ohmeow-blurr) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 27.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 43.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers->ohmeow-blurr) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers->ohmeow-blurr) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers->ohmeow-blurr) (4.41.1)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval->ohmeow-blurr) (2.3.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel->ohmeow-blurr) (0.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel->ohmeow-blurr) (1.12.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel->ohmeow-blurr) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->ohmeow-blurr) (47.1.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->ohmeow-blurr) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->ohmeow-blurr) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->ohmeow-blurr) (2.1.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->ohmeow-blurr) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->ohmeow-blurr) (0.7.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->ohmeow-blurr) (2.8.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->ohmeow-blurr) (4.6.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->ohmeow-blurr) (19.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2->ohmeow-blurr) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2->ohmeow-blurr) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2->ohmeow-blurr) (0.10.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->fastai2->ohmeow-blurr) (0.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2->ohmeow-blurr) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2->ohmeow-blurr) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2->ohmeow-blurr) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2->ohmeow-blurr) (2020.4.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->fastai2->ohmeow-blurr) (0.15.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai2->ohmeow-blurr) (2018.9)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (2.0.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (0.6.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->ohmeow-blurr) (7.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->ohmeow-blurr) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->ohmeow-blurr) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->ohmeow-blurr) (1.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0->ipykernel->ohmeow-blurr) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->ohmeow-blurr) (0.1.9)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai2->ohmeow-blurr) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai2->ohmeow-blurr) (3.1.0)\n",
            "Building wheels for collected packages: seqeval, sacremoses\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=afceab0220e51357df5fa466a44b248f2452247450d40e6ce12a608eccb7ac96\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=400051753dfddf7bd6d8216edf1c085c9be6992aeb428edd51a7c8d5eddcc7dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built seqeval sacremoses\n",
            "Installing collected packages: fastcore, fastai2, tokenizers, sentencepiece, sacremoses, transformers, seqeval, ohmeow-blurr\n",
            "Successfully installed fastai2-0.0.17 fastcore-0.1.17 ohmeow-blurr-0.0.5 sacremoses-0.0.43 sentencepiece-0.1.91 seqeval-0.0.12 tokenizers-0.7.0 transformers-2.11.0\n",
            "Collecting nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/69/17c95e9bdb431bb5102f331d3d34e0f3aabef14a8041690ad72c2b11d1d0/nlp-0.2.0-py3-none-any.whl (857kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 2.8MB/s \n",
            "\u001b[?25hCollecting pyarrow>=0.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/3f/6cac1714fff444664603f92cb9fbe91c7ae25375880158b9e9691c4584c8/pyarrow-0.17.1-cp36-cp36m-manylinux2014_x86_64.whl (63.8MB)\n",
            "\u001b[K     |████████████████████████████████| 63.8MB 44kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from nlp) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from nlp) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from nlp) (0.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from nlp) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from nlp) (1.18.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from nlp) (0.3.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (3.0.4)\n",
            "Installing collected packages: pyarrow, nlp\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "Successfully installed nlp-0.2.0 pyarrow-0.17.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw4soijJHgg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from fastai2.text.all import *\n",
        "from transformers import *\n",
        "import torch\n",
        "\n",
        "from blurr.data.all import *\n",
        "\n",
        "from blurr.modeling.all import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2e6_fQPI-Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"/content/drive/My Drive/semester 11/cse465/Project/dataset/LATEST/train.pt\"\n",
        "df = torch.load(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HptOoTUJXue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "f4a04b08-39f8-4cd4-b432-b92d4dc98a9f"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Abstract</th>\n",
              "      <th>Body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34616</th>\n",
              "      <td>We present three data driven model-types for COVID-19 with a minimal number of parameters to provide insights into the spread of the disease that may be used for developing policy responses. The first is exponential growth, widely studied in analysis of early-time data. The second is a self-exciting branching process model which includes a delay in transmission and recovery. It allows for meaningful fit to early time stochastic data. The third is the well-known Susceptible-Infected-Resistant (SIR) model and its cousin, SEIR, with an \"Exposed\" component. All three models are related quantit...</td>\n",
              "      <td>The world is in the midst of an ongoing pandemic, caused by the emergence of a novel coronavirus. Pharmaceutical interventions such as vaccination and anti-viral drugs are not currently available. In the short run, addressing the COVID-19 outbreak will depend critically on the successful implementation of public health measures including social distancing, workplace modifications, disease surveillance, contact tracing, isolation, and quarantine. \\n\\n On March 16th, Imperial College London released a report  predicting dire consequences if the US and UK did not swiftly take action. In respo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10388</th>\n",
              "      <td>Un bref descriptif des attitudes et représentations d'une patientèle de psychiatrie libérale parisienne relative à la pandémie SARS-CoV-2. Les données recueillies auprès de nos patients laissent entendre qu'ils ont accueilli la mesure de confinement de façon positive. Sa fin a été l'occasion d'un sursaut d'angoisse pour beaucoup. L'image du Covid-19 et celle du corps de l'autre ont eu tendance à se confondre. Une certaine perplexité relative aux mesures préventives a été observée.</td>\n",
              "      <td>Notre cabinet parisien a continué de fonctionner pendant toute la durée du confinement. La moitié des patients se sont absentés durant cette période et les autres ont maintenu le contact, principalement par téléconsultation. Le nombre de nouveaux patients a été très réduit. Nous décrivons ici les attitudes de nos patients devant l'épidémie ainsi que les représentations qu'ils ont pu développer de cette dernière dans le contexte du confinement. \\n\\n Il a été généralement bien observé, la plupart des patients disant le tolérer bien et profitant selon L'attitude générale, pour les adultes act...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27709</th>\n",
              "      <td>Endophytes are the group of microorganisms that reside to internal and healthy tissues without causing negative symptoms to their host plant. Endophytes are extremely diverse and range from fungi, bacteria and actinomycetes. Development of drug resistance to pathogenic forms of bacteria, fungi and other microbes, emergence of lethal viruses, the perpetuating epidemics in developing and under developing countries, and multifold fungal infection, enhancement in human population globally, all shows our inability to overcome these biomedical problems. In addition to this, we are also unable to...</td>\n",
              "      <td>Originally, the term endophyte was introduced by de Bary ( 1866 ) and was assigned to all those microbes that reside inside the living healthy tissues of the plants. Later, this term was expanded as fungi and bacteria including actinomycetes, which spend the whole or at least a part of their life cycle colonizing inter-or intra-cellularly, inside the healthy living tissue of the host plant, typically causing no apparent symptoms of disease. Many workers defi ne the endophytes in different ways, but Bacon and White ( 2000 ) gave a conclusive and widely accepted defi nition of endophyte as '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29449</th>\n",
              "      <td>Studies of proteinaceous cysteine protease inhibitors originated with the discovery of cystatins in the 1960s. Since that time, a rich and fascinating world of proteins that control and regulate a multitude of important physiological processes, ranging from the basics of protein turnover to development and brain function, has been uncovered. Failures in such important and complex systems inevitably lead to pathologies. Many threatening diseases such as cancer or neurological disorders, to mention only some, are attributed to deregulation of proteaseinhibitor balance. Moreover, important as...</td>\n",
              "      <td>The recent decade has witnessed tremendous development in the field of proteinaceous cysteine protease inhibitors. Though the prototype cystatins discovered in the 1960s remain the best-characterized group, several new large and a few smaller families are now recognized. Accordingly, the number of known physiological processes involving these proteins is rapidly increasing. In fact, it seems that wherever proteases are involved, proteinaceous regulators/protectants also appear on the stage. The role of such systems is best appreciated when the balance becomes upset. Consequently, deregulat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30950</th>\n",
              "      <td>The purpose of this study was to assess the value of metagenomic next-generation sequencing (mNGS) of bronchoalveolar lavage fluid (BALF) for the diagnosis of severe respiratory diseases based on interpretation of sequencing results. BALF samples were harvested and used for mNGS as well as microbiological detection. Infectious bacteria or fungi were defined according to relative abundance and number of unique reads. We performed mNGS on 35 BALF samples from 32 patients. The positive rate reached 100% in the mNGS analysis of nine immunocompromised patients. Compared with the culture method,...</td>\n",
              "      <td>The rational use of antibiotics is extremely important for immunocompromised and/or critically ill patients, for whom early aetiological diagnosis is necessary. However, traditional culture methods are time consuming and have low rates of positive detection. With the development of molecular biology, the value of whole genome-based next-generation sequencing (NGS) has gradually been recognized, especially for the detection of rare, atypical, or slow-growing microbes. NGS is mainly used in the clinical setting for assessment of sterile body fluids, including cerebrospinal fluid, blood, and ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Abstract                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Body\n",
              "34616  We present three data driven model-types for COVID-19 with a minimal number of parameters to provide insights into the spread of the disease that may be used for developing policy responses. The first is exponential growth, widely studied in analysis of early-time data. The second is a self-exciting branching process model which includes a delay in transmission and recovery. It allows for meaningful fit to early time stochastic data. The third is the well-known Susceptible-Infected-Resistant (SIR) model and its cousin, SEIR, with an \"Exposed\" component. All three models are related quantit...  The world is in the midst of an ongoing pandemic, caused by the emergence of a novel coronavirus. Pharmaceutical interventions such as vaccination and anti-viral drugs are not currently available. In the short run, addressing the COVID-19 outbreak will depend critically on the successful implementation of public health measures including social distancing, workplace modifications, disease surveillance, contact tracing, isolation, and quarantine. \\n\\n On March 16th, Imperial College London released a report  predicting dire consequences if the US and UK did not swiftly take action. In respo...\n",
              "10388                                                                                                                    Un bref descriptif des attitudes et représentations d'une patientèle de psychiatrie libérale parisienne relative à la pandémie SARS-CoV-2. Les données recueillies auprès de nos patients laissent entendre qu'ils ont accueilli la mesure de confinement de façon positive. Sa fin a été l'occasion d'un sursaut d'angoisse pour beaucoup. L'image du Covid-19 et celle du corps de l'autre ont eu tendance à se confondre. Une certaine perplexité relative aux mesures préventives a été observée.  Notre cabinet parisien a continué de fonctionner pendant toute la durée du confinement. La moitié des patients se sont absentés durant cette période et les autres ont maintenu le contact, principalement par téléconsultation. Le nombre de nouveaux patients a été très réduit. Nous décrivons ici les attitudes de nos patients devant l'épidémie ainsi que les représentations qu'ils ont pu développer de cette dernière dans le contexte du confinement. \\n\\n Il a été généralement bien observé, la plupart des patients disant le tolérer bien et profitant selon L'attitude générale, pour les adultes act...\n",
              "27709  Endophytes are the group of microorganisms that reside to internal and healthy tissues without causing negative symptoms to their host plant. Endophytes are extremely diverse and range from fungi, bacteria and actinomycetes. Development of drug resistance to pathogenic forms of bacteria, fungi and other microbes, emergence of lethal viruses, the perpetuating epidemics in developing and under developing countries, and multifold fungal infection, enhancement in human population globally, all shows our inability to overcome these biomedical problems. In addition to this, we are also unable to...  Originally, the term endophyte was introduced by de Bary ( 1866 ) and was assigned to all those microbes that reside inside the living healthy tissues of the plants. Later, this term was expanded as fungi and bacteria including actinomycetes, which spend the whole or at least a part of their life cycle colonizing inter-or intra-cellularly, inside the healthy living tissue of the host plant, typically causing no apparent symptoms of disease. Many workers defi ne the endophytes in different ways, but Bacon and White ( 2000 ) gave a conclusive and widely accepted defi nition of endophyte as '...\n",
              "29449  Studies of proteinaceous cysteine protease inhibitors originated with the discovery of cystatins in the 1960s. Since that time, a rich and fascinating world of proteins that control and regulate a multitude of important physiological processes, ranging from the basics of protein turnover to development and brain function, has been uncovered. Failures in such important and complex systems inevitably lead to pathologies. Many threatening diseases such as cancer or neurological disorders, to mention only some, are attributed to deregulation of proteaseinhibitor balance. Moreover, important as...  The recent decade has witnessed tremendous development in the field of proteinaceous cysteine protease inhibitors. Though the prototype cystatins discovered in the 1960s remain the best-characterized group, several new large and a few smaller families are now recognized. Accordingly, the number of known physiological processes involving these proteins is rapidly increasing. In fact, it seems that wherever proteases are involved, proteinaceous regulators/protectants also appear on the stage. The role of such systems is best appreciated when the balance becomes upset. Consequently, deregulat...\n",
              "30950  The purpose of this study was to assess the value of metagenomic next-generation sequencing (mNGS) of bronchoalveolar lavage fluid (BALF) for the diagnosis of severe respiratory diseases based on interpretation of sequencing results. BALF samples were harvested and used for mNGS as well as microbiological detection. Infectious bacteria or fungi were defined according to relative abundance and number of unique reads. We performed mNGS on 35 BALF samples from 32 patients. The positive rate reached 100% in the mNGS analysis of nine immunocompromised patients. Compared with the culture method,...  The rational use of antibiotics is extremely important for immunocompromised and/or critically ill patients, for whom early aetiological diagnosis is necessary. However, traditional culture methods are time consuming and have low rates of positive detection. With the development of molecular biology, the value of whole genome-based next-generation sequencing (NGS) has gradually been recognized, especially for the detection of rare, atypical, or slow-growing microbes. NGS is mainly used in the clinical setting for assessment of sterile body fluids, including cerebrospinal fluid, blood, and ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFbB9sYwJgZ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7108849c-c9ae-41aa-8c27-af2388f5f76a"
      },
      "source": [
        "print(len(df))\n",
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41506\n",
            "(41506, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EAKDnu0iU_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# train, test= train_test_split(df, test_size=0.10, random_state=42)\n",
        "# # train_df = df.loc[0:8500]\n",
        "# # test_df = df.loc[8501:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3Wd6kZtiq1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5e53c632-1213-4f1c-cb8e-11ca301adeb9"
      },
      "source": [
        "# print(len(train))\n",
        "# print(len(test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41506\n",
            "4612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8eEUxSLj40s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.save(train,\"/content/drive/My Drive/semester 11/cse465/Project/dataset/LATEST/train.pt\")\n",
        "# torch.save(test,\"/content/drive/My Drive/semester 11/cse465/Project/dataset/LATEST/test.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP2wDM-lJvZd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "7bd3f332def346afac7dacba83e807c4",
            "ebfdf3c4e328487baa8f5469cdf94f1f",
            "1b661d8b010348fa936e58c097071fe2",
            "3ee0f74fe20b4bfba0290f4f73dd52a2",
            "e7d8eb52bf524053b0f59af4a213bab0",
            "050e967ec01a41bfbce532291a101e1e",
            "b0d71865fdec41bcb92bbc3d2fcf71f0",
            "4bcf09fe7b704f7cb2118217567c3c26",
            "c13cda9c5bc44596871256f6d29c8d75",
            "d2ea122559d949e8aae0e671f940e588",
            "d40151364c784855981fd3fbb343b2d9",
            "5f199d95e4514499aed60139c4394b43",
            "0287b5b80563471a9b1e2e8cf4807b76",
            "ab1e517e21af413f8507eaf73d426a0e",
            "c4511a0d19154697b971a73963bbdad6",
            "1a795c8acac44d6aadcfefee7a4289ea",
            "208ade4e39bb4790a74eba1375764392",
            "589963d68bd84033b949b08060d55ca9",
            "13da4546227042cbbee7cb6152cbec9d",
            "cab3e8400293482e9685e741a5728d3d",
            "7e3691a5635a48fd96ea4c13711d072f",
            "2576b722c3ff4adb955164776729885f",
            "14d992d0e9344517bfdb47840d6f724c",
            "17b3369ac4d9459a9e4a52a006bb5b62",
            "eab6795ac63c45a089404b51782d8acc",
            "ce4afd8ce922450e949daa7e86023682",
            "d0d696a3fd29495d9df225cbde64ed86",
            "ea3bf49063b44f119efd04ae4f0eeb8d",
            "8a25395499094b45b7bc66b92406dad7",
            "e08c3058d27f48e29f2b71a6023c3619",
            "a1b0743a53274c8ea9e02bbdce162542",
            "fe4406ba28b7402c9a42576abc62865a"
          ]
        },
        "outputId": "094406be-cf03-4d7b-ee25-0eef245ab2d6"
      },
      "source": [
        "pretrained_model_name = \"bart-large-cnn\"\n",
        "hf_arch, hf_tokenizer, hf_config, hf_model = \\\n",
        "    BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, BartTokenizer, HF_MODELS.BartForConditionalGeneration)\n",
        "hf_arch, type(hf_tokenizer), type(hf_config), type(hf_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7bd3f332def346afac7dacba83e807c4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c13cda9c5bc44596871256f6d29c8d75",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "208ade4e39bb4790a74eba1375764392",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1300.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eab6795ac63c45a089404b51782d8acc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1625270765.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('bart',\n",
              " transformers.tokenization_bart.BartTokenizer,\n",
              " transformers.configuration_bart.BartConfig,\n",
              " transformers.modeling_bart.BartForConditionalGeneration)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wbnHl48Jz6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "blocks = ( \n",
        "    HF_TextBlock(hf_arch, hf_tokenizer), \n",
        "    HF_TextBlock(hf_arch, hf_tokenizer, task=ForConditionalGenerationTask())\n",
        ")\n",
        "\n",
        "dblock = DataBlock(blocks=blocks, \n",
        "                   get_x=ColReader('Body'), \n",
        "                   get_y=ColReader('Abstract'), \n",
        "                   splitter=RandomSubsetSplitter(0.05, 0.01))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4NZwLHzMGkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dls = dblock.dataloaders(df, bs=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_KaQDeYQDZU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5046bc16-496c-466a-8a82-974e0d29aa58"
      },
      "source": [
        "# a = dls.one_batch()\n",
        "# len(a[0]), a[0][0].shape,a[1].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, torch.Size([4, 512]), torch.Size([4, 300]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnOMUeHSOvya",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3e6e27d-c231-44df-92d0-d996062d9516"
      },
      "source": [
        "b = dls.one_batch()\n",
        "len(b), b[0][0].shape, b[1].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, torch.Size([4, 512]), torch.Size([4, 512]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfBuw_3HO5Ys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "outputId": "bbee3703-1de8-405c-fafc-d5a442098751"
      },
      "source": [
        "dls.show_batch(hf_tokenizer=hf_tokenizer, max_n=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The research protocol described here follows directly from a recently completed NCCAM-funded study (1R01AT004313) in which we randomized n=154 people to 3 groups: 1) 8-weeks of training in mindfulness meditation, 2) matched 8-weeks of training in exercise, or 3) wait list control. A total of 94 participants were randomized in September 2009, and 60 more in January 2010. Only 5 withdrew early, with 149 followed through May 2010. There were 27 ARI episodes and 257 days of ARI illness in the meditation group (n=51) and 26 episodes and 241 ARI illness days for exercise (n=47), compared to 40 episodes and 453 ARI illness days for the control group (n=51). Mean area-under-curve global severity was 144 for meditation, 248 for exercise, and 358 for control. Comparing meditation to control, one-sided T-test yielded P=0.034 for illness days and p=0.0042 for global severity. Comparing exercise to control, corresponding p-values were 0.032 for illness days and 0.16 for global severity. Adjusting for covariates with zero-inflated multivariate regression models, both total days of illness (p=0.033) and global severity (p=0.010) appeared to be lower for meditation, but not for exercise (p = 0.47 and p=0.31, respectively). There were 16 ARI-related health care visits and 67 sick days lost to work in the control group, compared to 15 visits and 32 sick days for exercise and 10 visits and 16 sick days for meditation. Multiplex polymerase chain reaction (PCR) confirmed virus in 19 of the control episodes, 14 for meditation, and 8 for exercise. The only 2 cases of confirmed influenza were in the control group. Neutrophil counts and interleukin-8 (IL-8) assays provided corroborating evidence that observed benefits were unlikely to be due to biased-self-report biases. 1 \\n\\nTo the best of our knowledge, the preliminary research described above is the first randomized trial to assess potential influences of mindfulness meditation on ARI illness, and the first to use a validated outcome measure to assess effects of exercise on ARI illness. It is also the first to compare both meditation and exercise to a valid control group, allowing head-to-head comparative effectiveness assessment. The proposed work is also innovative in terms</td>\n",
              "      <td>Lactogenic immunity transferred to piglets after inoculation of a live vaccine to pregnant sows was proved limited to control porcine epidemic diarrhea (PED). Hence, here we evaluated the efficacy of administration of a probiotic compound containing Bacillus mesentericus, Clostridium butyricum, and Enterococcus faecalis together with a commercial live-attenuated PED vaccine (Nisseiken PED Live Vaccine, Nisseiken, Tokyo, Japan) to improve the health and reproductive performance of PED-infected sows. Twenty pregnant sows in a PED-positive farm were equally divided into probiotics-administered (VP) and control (VC) sow groups. A commercial live-attenuated vaccine was injected as per the manufacturer's instruction. The probiotic compound (15 g/day) was orally administered to VP from 6 weeks pre-parturition to 7 days post-parturition (ppd7). VP had a significantly higher body weight at ppd7 than VC (191 vs 186 kg; P &lt; 0.05). At day 3 post-parturition (ppd3) (4.18 vs 3.63 kg/day) and ppd7 (5.14 vs 4.34 kg/day), milk produced by VP was significantly (P &lt; 0.05) greater than that by VC. Total immunoglobulin (Ig)A and IgG concentrations at day 0 were significantly (P &lt; 0.05) higher in whey of VP (1.9 and 6.6 g/dL, respectively) than in that of VC (1.7 and 6.1 g/dL, respectively). However, total IgG concentration in whey of VP and VC at ppd3 and ppd7 did not differ. Antibody titer was significantly higher at day 0 in serum of VP than it was that of VC (60 vs 37 in geometric mean; P &lt; 0.05). Likewise, the antibody titer in whey of VP and VC was found to be similar at day 0 (416 vs 208 in geometric mean; P = 0.13). Consequently, VP had fewer days between weaning and return to estrus than did VC (7 vs 10 days; P &lt; 0.05). Moreover, piglets of VP had a significantly (P &lt; 0.05) higher litter weight at birth (9,252 g/litter) and a lower mortality (12%) during suckling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Schizophrenia is a devastating illness that affects over 2 million people in the U.S. and displays a wide range of symptoms      . Cognitive impairment is a hallmark feature of the illness, and antipsychotics have poor efficacy in treating cognitive decline (7, 8). The dorsolateral prefrontal cortex (DLPFC) is a brain region heavily implicated in the pathophysiology of schizophrenia, possibly contributing to defects in working memory . A variety of abnormalities have been reported in the DLPFC of schizophrenia patients, including changes in gene expression, cell density, receptor binding, and cerebral blood flow   . \\n\\n There is also accumulating evidence of bioenergetic dysfunction in chronic schizophrenia, which has recently been reviewed and highlights a number of abnormalities associated with glucose metabolism, the lactate shuttle, and bioenergetic coupling . There is also evidence for genetic linkage between enzymes that control glycolysis in schizophrenia including 6phosphofructo-2-kinase/fructose-2,6-bisphosphatase 2 (PFKFB2) and hexokinase 3 (HK3), suggesting that genetic risk for this illness includes bioenergetic substrates . Interestingly, studies using cell-level techniques have demonstrated complex bioenergetic changes, including decreases in mitochondrial oxidative energy metabolism genes in dentate granule neurons (n=22) and in layer 3 and 5 pyramidal neurons from the DLPFC (n=36 and n=19)   . \\n\\n Decreases in metabolic transcripts included lactate dehydrogenase A (LDHA), nicotinamide adenine dinucleotide dehydrogenases (NADH), and ATP synthases. We have also recently demonstrated decreases in glycolytic enzymes (HK1, and phosphofructokinase muscle type, PFKM) and glucose transporters (GLUT1 and GLUT3) in pyramidal neurons, but not astrocytes, in the DLPFC of schizophrenia subjects (n=16) . While examining the expression of individual targets is important, employing a signature based bioinformatics approach may help elucidate the pathophysiology of large biological networks. gene to determine if a knockdown signature has been catalogued in the database. By clustering the seed gene knockdown signatures in iLINCS, we are able to analyze the connectivity of the knockdown signatures (and thus establish a schizophrenia bioenergetic profile), identifying groups of L</td>\n",
              "      <td>Infection of the CNS (central nervous system) with a sublethal neurotropic coronavirus (JHMV) induces a vigorous inflammatory response. CD4 + and CD8 + T cells are essential to control infectious virus but at the cost of tissue damage. An enigma in understanding the contribution of T cell subsets in pathogenesis resides in their distinct migration pattern across the BBB (blood brain barrier). CD4 + T cells transiently accumulate within the perivascular space, whereas CD8 + T cells migrate directly into the CNS parenchyma. As MMPs (matrix metalloproteinases) facilitate migration across the glia limitans, specific expression of the TIMP (tissue inhibitor of MMPs)-1 by CD4 + T cells present in the perivascular cuffs suggested that TIMP-1 is responsible for stalling CD4 + T cell migration into the CNS parenchyma. Using TIMP-1 deficient mice, the present data demonstrate an increase rather than a decrease in CD4 + T cell accumulation within the perivascular space during JHMV infection. Whereas virus control was not affected by perivascular retention of CD4 + T cells, disease severity was decreased and associated with reduced IFNγ (interferon γ) production. Moreover, decreased CD4 + T cell recruitment into the CNS parenchyma of TIMP-1 deficient mice was not associated with impaired T cell recruiting chemokines or MMP expression, and no compensation by other TIMP molecules was identified. These data suggest an MMP-independent role of TIMP-1 in regulating CD4 + T cell access into the CNS parenchyma during acute JHMV encephalitis.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBU7Gfxyp-AZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f4ee7f8-80ca-4aa7-eaab-8662021b135b"
      },
      "source": [
        "hf_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BartForConditionalGeneration(\n",
              "  (model): BartModel(\n",
              "    (shared): Embedding(50264, 1024, padding_idx=1)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
              "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
              "      (layers): ModuleList(\n",
              "        (0): EncoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): EncoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): EncoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): EncoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): EncoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): EncoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (6): EncoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (7): EncoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (8): EncoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (9): EncoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (10): EncoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (11): EncoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
              "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
              "      (layers): ModuleList(\n",
              "        (0): DecoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): DecoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): DecoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): DecoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): DecoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): DecoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (6): DecoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (7): DecoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (8): DecoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (9): DecoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (10): DecoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (11): DecoderLayer(\n",
              "          (self_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): SelfAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IIRrDj7PaPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = HF_TextGenerationModelWrapper(hf_model)\n",
        "\n",
        "learn = Learner(dls, \n",
        "                model,\n",
        "                opt_func=ranger,\n",
        "                loss_func=CrossEntropyLossFlat(ignore_index=hf_tokenizer.pad_token_id),\n",
        "                cbs=[HF_BaseModelCallback],\n",
        "                splitter=partial(text_gen_splitter, arch=hf_arch)).to_fp16()\n",
        "\n",
        "learn.create_opt() \n",
        "learn.freeze_to(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsyG91Ndpq8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yGMkXQ1aAgN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "d77c0386-6b13-4954-aae0-de8dd86343c3"
      },
      "source": [
        "learn.lr_find(suggestions=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(lr_min=1.58489319801447e-07, lr_steep=1.3182567499825382e-06)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYmLMRqZTzb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# b = dls.one_batch()\n",
        "# preds = learn.model(b[0])\n",
        "# len(b), len(b[0]), b[0][0].shape, len(b[1]), b[1].shape, len(preds), preds[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw1A5MKQUP_T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "4096379e-03ae-4237-9c70-936c798053be"
      },
      "source": [
        "learn.fit(3,lr=3e-5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.791651</td>\n",
              "      <td>2.712018</td>\n",
              "      <td>1:17:40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.628802</td>\n",
              "      <td>2.653870</td>\n",
              "      <td>1:29:57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.354951</td>\n",
              "      <td>2.649674</td>\n",
              "      <td>1:31:33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmBCw_tM_4VY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save(\"/content/drive/My Drive/semester 11/cse465/Project/dataset/models/covid-19\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFb3xFbYTNVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.export(\"/content/drive/My Drive/semester 11/cse465/Project/dataset/models/covid-19.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQWXwsmYWQzu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "outputId": "b14466d1-113c-42f5-bfaf-69a7f2ff0a1a"
      },
      "source": [
        "print( learn.show_results(hf_tokenizer=hf_tokenizer, max_n=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Today there is a fast growing number of nucleic acid-based strategies to modulate a vast variety of cellular functions (for a review see:  ). Several classes of oligonucleotides like aptamers, transcription factor-binding decoy oligonucleotides, ribozymes, triplex-forming oligonucleotides (TFO), immunostimulatory CpG motifs, antisense oligonucleotides including peptide nucleic acids (PNAs), small interfering RNAs (siRNAs) and antagomirs have attained much interest as a research tool owing to their highly specific mode of action. Even more important, these oligomeric nucleic acids do have a considerable potential to be used as therapeutics. Figure 1 provides an overview of such oligonucleotides and their target sites within the cell. Aptamers, small oligonucleotides derived from an in vitro evolution process called SELEX, can virtually be targeted to any given extra-or intracellular structure. Oligonucleotides containing a CpG motif interact with toll-like receptor 9 (TLR9) and trigger an immunostimulatory response. Antisense and decoy oligonucleotides as well as siRNAs can modulate gene expression by interacting with RNA or proteins either in the cytoplasm or in the nucleus. TFOs are directed against genomic DNA and, like plasmids, have to reach the nucleus to exert their biological effect.\\n\\nAlthough quite different in their mode of action, oligomeric nucleic acids have several features in common. Essentially, they can either be rationally designed (e.g. antisense oligonucleotides or siRNAs) or selected in vitro (e.g. aptamers or ribozymes). These are major advantages compared to traditional small molecule drug screening approaches. In general, these macromolecules show remarkably high specificity for their targets accompanied by low probability of generating side-effects. Additionally, nucleic acids are virtually non-immunogenic compared to protein-or peptide-based approaches. On the downside, considerations like stability, bio-availability and pharmacokinetics come into play. Though, these drawbacks can be resolved by appropriate chemical modifications. Nuclease resistance for instance can be achieved by alkyl modifications at the 2'-position of the ribose. In recent years, valuable progress has been accomplished through the development of novel chemically modified nucle</td>\n",
              "      <td>Background: Should an emerging infectious disease outbreak or an environmental disaster occur, the collection of epidemiological data must start as soon as possible after the event's onset. Questionnaires are usually built de novo for each event, resulting in substantially delayed epidemiological responses that are detrimental to the understanding and control of the event considered. Moreover, the public health and/or academic institution databases constructed with responses to different questionnaires are usually difficult to merge, impairing necessary collaborations. We aimed to show that e-commerce concepts and software tools can be readily adapted to enable rapid collection of data after an infectious disease outbreak or environmental disaster. Here, the 'customers' are the epidemiologists, who fill their shopping 'baskets' with standardised questions. Methods: For each epidemiological field, a catalogue of questions is constituted by identifying the relevant variables based on a review of the published literature on similar circumstances. Each question is tagged with information on its source papers. Epidemiologists can then tailor their own questionnaires by choosing appropriate questions from this catalogue. The software immediately provides them with ready-to-use forms and online questionnaires. All databases constituted by the different EpiBasket users are interoperable, because the corresponding questionnaires are derived from the same corpus of questions. Results: A proof-of-concept prototype was developed for Knowledge, Attitudes and Practice (KAP) surveys, which is one of the fields of the epidemiological investigation frequently explored during, or after, an outbreak or environmental disaster. The catalogue of questions was initiated from a review of the KAP studies conducted during or after the 2003 severe acute respiratory syndrome epidemic. Conclusion: Rapid collection of standardised data after an outbreak or environmental disaster can be facilitated by transposing the e-commerce paradigm to epidemiology, taking advantage of the powerful software tools already available.</td>\n",
              "      <td>Background: The a experimental pand disease be require a emerging disaster occur? an appropriate and physicaliological and should</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The main differences between Sepsis-3 and previous versions are that Sepsis-3 eliminated the terms sepsis syndrome and severe sepsis, and introduced a new definition of sepsis, which is more comparable to the older definition of severe sepsis. In addition, the systemic inflammatory response syndrome (SIRS) criteria, which were the essential elements of Sepsis-1 and Sepsis-2, are no longer used to define sepsis, but they still play a role in the recognition of infection and warrant early intervention for possible sepsis (1, 4). Sepsis-3 provides a more specific and universal definition for sepsis, which would improve clinical management and facilitate epidemiological surveys. It also has better predictive ability for in-hospital mortality .\\n\\nHowever, Sepsis-3 is not designed for paediatric populations, which carry a high burden of sepsis . The current, widelyused consensus definition of paediatric sepsis, proposed in 2005, was still built on the SIRS criteria . It has been shown to lack specificity and perform poorly in identifying children at high risk of mortality from infection   . In addition, its feasibility and applicability when applying to a non-intensive care setting or low-and middle-income countries remain questionable . Some evidence has suggested it may be useful to apply the Sepsis-3 definition to paediatric populations (8,   . However, many children with severe viral respiratory tract infections (e.g., bronchiolitis) fulfil the criteria for viral sepsis, but generally clinicians would not regard them as \"septic, \" highlighting the difficulty in providing a robust definition of viral sepsis . Therefore, there is an urgent need to convene a consensus task force and design a paediatric definition (9, 14).\\n\\nAlthough bacterial or fungal infections are commonly attributed as the cause of sepsis, sepsis is infrequently attributed to viral infections. In some cases, viral sepsis is regarded as virus-induced direct tissue or cell damage (e.g., influenza virus-induced pulmonary epithelial damage) instead of systemic dysregulation caused by virus. However, the abovementioned consensus definitions of sepsis, either for adult  or paediatric  populations are not pathogen-specific, so the same definitions should also apply to viral infection. Therefore, in this review article, viral sepsis is defined as life-threatening organ dysfunction</td>\n",
              "      <td>We evaluated the presence of coronaviruses by PCR in 918 Australian wild bird samples collected during 2016-17. Coronaviruses were detected in 141 samples (15.3%) from species of ducks, shorebirds and herons and from multiple sampling locations. Sequencing of selected positive samples found mainly gammacoronaviruses, but also some deltacoronaviruses. The detection rate of coronaviruses was improved by using multiple PCR assays, as no single assay could detect all coronavirus positive samples. Sequencing of the relatively conserved Orf1 PCR amplicons found that Australian duck gammacoronaviruses were similar to duck gammacoronaviruses around the world. Some sequenced shorebird gammacoronaviruses belonged to Charadriiformes lineages, but others were more closely related to duck gammacoronaviruses. Australian duck and heron deltacoronaviruses belonged to lineages with other duck and heron deltacoronaviruses, but were almost 20% different in nucleotide sequence to other deltacoronavirus sequences available. Deltacoronavirus sequences from shorebirds formed a lineage with a deltacoronavirus from a ruddy turnstone detected in the United States. Given that Australian duck gammacoronaviruses are highly similar to those found in other regions, and Australian ducks rarely come into contact with migratory Palearctic duck species, we hypothesise that migratory shorebirds are the important vector for moving wild bird coronaviruses into and out of Australia.</td>\n",
              "      <td>Background describe the feasibility of infectiousavirususes in using in the- patients primary- (. from the.17. Theonaviruses were</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q05Y7yaHmo-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_article = \"\"\"\n",
        "Today there is a fast growing number of nucleic acid-based strategies to modulate a vast variety of cellular functions (for a review see: ). Several classes of oligonucleotides like aptamers, transcription factor-binding decoy oligonucleotides, ribozymes, triplex-forming oligonucleotides (TFO), immunostimulatory CpG motifs, antisense oligonucleotides including peptide nucleic acids (PNAs), small interfering RNAs (siRNAs) and antagomirs have attained much interest as a research tool owing to their highly specific mode of action. Even more important, these oligomeric nucleic acids do have a considerable potential to be used as therapeutics. Figure 1 provides an overview of such oligonucleotides and their target sites within the cell. Aptamers, small oligonucleotides derived from an in vitro evolution process called SELEX, can virtually be targeted to any given extra-or intracellular structure. Oligonucleotides containing a CpG motif interact with toll-like receptor 9 (TLR9) and trigger an immunostimulatory response. Antisense and decoy oligonucleotides as well as siRNAs can modulate gene expression by interacting with RNA or proteins either in the cytoplasm or in the nucleus. TFOs are directed against genomic DNA and, like plasmids, have to reach the nucleus to exert their biological effect.\\n\\nAlthough quite different in their mode of action, oligomeric nucleic acids have several features in common. Essentially, they can either be rationally designed (e.g. antisense oligonucleotides or siRNAs) or selected in vitro (e.g. aptamers or ribozymes). These are major advantages compared to traditional small molecule drug screening approaches. In general, these macromolecules show remarkably high specificity for their targets accompanied by low probability of generating side-effects. Additionally, nucleic acids are virtually non-immunogenic compared to protein-or peptide-based approaches. On the downside, considerations like stability, bio-availability and pharmacokinetics come into play.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LntbfiyaqksX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "4089f5ce-d294-4cfa-deef-133b4daed41b"
      },
      "source": [
        "# outputs = learn.generate_text(test_article, early_stopping=True, num_beams=4, num_return_sequences=3)\n",
        "\n",
        "# for idx, o in enumerate(outputs):\n",
        "#     print(f'=== Prediction {idx+1} ===\\n{o}\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Prediction 1 ===\n",
            " Background: Although quite different in their mode of action, oligomeric nucleic acids have several features in common. Essentially, they can either be rationally designed (e.g. antisense oligonucleotides or siRNAs) or selected in vitro. These are major advantages compared to traditional small molecule drug screening approaches. On the downside, considerations like stability, bio-availability and pharmacokinetics come into play.\n",
            "\n",
            "=== Prediction 2 ===\n",
            " Although quite different in their mode of action, oligomeric nucleic acids have several features in common. Essentially, they can either be rationally designed (e.g. antisense oligonucleotides or siRNAs) or selected in vitro. These are major advantages compared to traditional small molecule drug screening approaches. On the downside, considerations like stability, bio-availability and pharmacokinetics come into play.\n",
            "\n",
            "=== Prediction 3 ===\n",
            " Background: Although quite different in their mode of action, oligomeric nucleic acids have several features in common. Essentially, they can either be rationally designed (e.g. antisense oligonucleotides or siRNAs) or selected in vitro. These are major advantages compared to traditional small molecule drug screening approaches.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NddpvyIHVNcH",
        "colab_type": "text"
      },
      "source": [
        "## ***Inference ***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AnNCKmhZznF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "4da76d04-4968-4e84-b4d3-1fbcfe266617"
      },
      "source": [
        "learn = load_learner(\"/content/drive/My Drive/semester 11/cse465/Project/dataset/models/covid-19.pkl\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'transformers.modeling_bart.BartForConditionalGeneration' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSpbsxY9bYAr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9439f06d-c749-4fad-d59d-d335d4d7bd84"
      },
      "source": [
        "# learn.generate_text(test_article)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Aptamers, small oligonucleotides derived from an in vitro evolution process called SELEX, can virtually be targeted to any given extra-or intracellular structure. Oligomeric nucleic acids containing a CpG motif interact with toll-like receptor 9 (TLR9) and trigger an immunostimulatory response. Antisense and decoy oligon nucleotides as well as siRNAs can modulate gene expression by interacting with RNA or proteins either in the cytoplasm or in the nucleus. TFOs are directed against genomic DNA and, like plasmids,']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw-Y-G5GSJLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = torch.load(\"/content/drive/My Drive/semester 11/cse465/Project/dataset/LATEST/test.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_pY7RRMZo8j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "bc69dcc2-3dad-4ab5-d1d5-c49dcad159d1"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Abstract</th>\n",
              "      <th>Body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14125</th>\n",
              "      <td>Background: The spike glycoprotein (S) gene of the severe acute respiratory syndrome-associated coronavirus (SARS-CoV) has been useful in analyzing the molecular epidemiology of the 2003 SARS outbreaks. Objectives: To characterize complete SARS-CoV S-gene sequences from Hong Kong. Study design: Fifty-six SARS-CoV S-gene sequences, obtained from patients who presented with SARS to the Prince of Wales Hospital during March-May 2003, were analysed using a maximum likelihood (ML) approach, together with 138 other (both human and animal) S-gene sequences downloaded from GenBank. Results: The ma...</td>\n",
              "      <td>Since the severe acute respiratory syndrome (SARS) epidemic of 2003 around the world, many researchers have attempted to determine the natural reservoir of the SARS-associated coronavirus (SARS-CoV). Studies on the possible animal source of SARS-CoV have mainly focused on the Himalyan palm civet (Paguma larvata), though other animals (e.g. the raccoon dog, Nyctereutes procyonoides) have been shown to carry coronaviruses closely related to the SARS-CoV. Of note, these related animal coronaviruses possess a 29 base-pair sequence (position 27,869-27,897) in the 1386-6532/$ -see front matter ©...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3401</th>\n",
              "      <td>Influenza usually spreads through the human population in multiple-wave outbreaks. Successive reinfection of individuals over a short time interval has been explicitly reported during past pandemics. However, the causes of rapid reinfection and the role of reinfection in driving multiple-wave outbreaks remain poorly understood. To investigate these issues, we focus on a two-wave influenza A/H3N2 epidemic that occurred on the remote island of Tristan da Cunha in 1971. Over 59 days, 273 (96%) of 284 islanders experienced at least one attack and 92 (32%) experienced two attacks. We formulate ...</td>\n",
              "      <td>A swine-origin influenza A/H1N1 virus that arose in 2009 reminds us of the persistent risk of influenza pandemics. Lessons from the past are precious and may help us to anticipate and manage such potential disasters  . The most striking example is certainly the 'Spanish' influenza pandemic of 1918 -1919 that occurred in three waves and caused about 50 million deaths worldwide in only nine months  . To date, this multiple-wave outbreak pattern, which has also been reported during several other pandemic episodes, remains only partially understood. On one hand, there is evidence from the 2009...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29313</th>\n",
              "      <td>Touristic cities will suffer from COVID-19 emergency because of its economic impact on their communities. The first emergency phases involved a wide closure of such areas to support \"social distancing\" measures (i.e. travels limitation; lockdown of (over)crowd-prone activities). In the second phase, individual's risk-mitigation strategies (facial masks) could be properly linked to \"social distancing\" to ensure re-opening touristic cities to visitors. Simulation tools could support the effectiveness evaluation of risk-mitigation measures to look for an economic and social optimum for activi...</td>\n",
              "      <td>The smart adaptation of cities against different risks is one of the key challenges for their sustainability and the resilience of the hosted communities (C. Ribeiro and Pena Jardim Gonçalves, 2019) . Urban areas involved by tourists' flows represent a particular application context for such resilience issues, because of the complexity between economic, social (including relationships between tourists' and residents' needs) and organizational tasks, especially in those scenarios in which seasonal tourism is a training element for the community (Feleki et al., 2018; Qie and Rong, 2016; Stan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12609</th>\n",
              "      <td>Background. Effective influenza surveillance requires new methods capable of rapid and inexpensive genomic analysis of evolving viral species for pandemic preparedness, to understand the evolution of circulating viral species, and for vaccine strain selection. We have developed one such approach based on previously described broad-range reverse transcription PCR/ electrospray ionization mass spectrometry (RT-PCR/ESI-MS) technology. Methods and Principal Findings. Analysis of base compositions of RT-PCR amplicons from influenza core gene segments (PB1, PB2, PA, M, NS, NP) are used to provid...</td>\n",
              "      <td>Influenza viruses cause serious global economic and public health burdens. Annual influenza epidemics resulted in more than 30,000 deaths a year in the United States during 1990-1999  . Periodic pandemics result in significantly higher death tolls. Emergence of new influenza A virus strains can be caused by ''antigenic shift,'' resulting from reassortment of gene segments, including H and/or N types  , ''antigenic drift'' resulting from the continuing accumulation of mutations in the H and N genes  , or a pathogenic virus jumping species and acquiring the ability to infect and be transmitt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17432</th>\n",
              "      <td>Memory CD8 T cells can provide protection from re-infection by respiratory viruses such as influenza and SARS. However, the relative contribution of memory CD8 T cells in providing protection against respiratory syncytial virus (RSV) infection is currently unclear. To address this knowledge gap, we utilized a prime-boost immunization approach to induce robust memory CD8 T cell responses in the absence of RSV-specific CD4 T cells and antibodies. Unexpectedly, RSV infection of mice with pre-existing CD8 T cell memory led to exacerbated weight loss, pulmonary disease, and lethal immunopatholo...</td>\n",
              "      <td>a1111111111 a1111111111 a1111111111 a1111111111 a1111111111 \\n\\n Respiratory syncytial virus (RSV) is a major cause of severe disease in young children, the elderly, and immunocompromised populations  . Furthermore, RSV is the leading cause of infant hospitalizations creating an immense healthcare burden for treatment and prevention  . There is currently no licensed vaccine for RSV. During a primary RSV infection, the CD8 T cell response is crucial for mediating viral clearance  . Depletion of CD8 T cells in mice prior to RSV challenge leads to elevated viral loads, but also ameliorates mo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Abstract                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Body\n",
              "14125  Background: The spike glycoprotein (S) gene of the severe acute respiratory syndrome-associated coronavirus (SARS-CoV) has been useful in analyzing the molecular epidemiology of the 2003 SARS outbreaks. Objectives: To characterize complete SARS-CoV S-gene sequences from Hong Kong. Study design: Fifty-six SARS-CoV S-gene sequences, obtained from patients who presented with SARS to the Prince of Wales Hospital during March-May 2003, were analysed using a maximum likelihood (ML) approach, together with 138 other (both human and animal) S-gene sequences downloaded from GenBank. Results: The ma...  Since the severe acute respiratory syndrome (SARS) epidemic of 2003 around the world, many researchers have attempted to determine the natural reservoir of the SARS-associated coronavirus (SARS-CoV). Studies on the possible animal source of SARS-CoV have mainly focused on the Himalyan palm civet (Paguma larvata), though other animals (e.g. the raccoon dog, Nyctereutes procyonoides) have been shown to carry coronaviruses closely related to the SARS-CoV. Of note, these related animal coronaviruses possess a 29 base-pair sequence (position 27,869-27,897) in the 1386-6532/$ -see front matter ©...\n",
              "3401   Influenza usually spreads through the human population in multiple-wave outbreaks. Successive reinfection of individuals over a short time interval has been explicitly reported during past pandemics. However, the causes of rapid reinfection and the role of reinfection in driving multiple-wave outbreaks remain poorly understood. To investigate these issues, we focus on a two-wave influenza A/H3N2 epidemic that occurred on the remote island of Tristan da Cunha in 1971. Over 59 days, 273 (96%) of 284 islanders experienced at least one attack and 92 (32%) experienced two attacks. We formulate ...  A swine-origin influenza A/H1N1 virus that arose in 2009 reminds us of the persistent risk of influenza pandemics. Lessons from the past are precious and may help us to anticipate and manage such potential disasters  . The most striking example is certainly the 'Spanish' influenza pandemic of 1918 -1919 that occurred in three waves and caused about 50 million deaths worldwide in only nine months  . To date, this multiple-wave outbreak pattern, which has also been reported during several other pandemic episodes, remains only partially understood. On one hand, there is evidence from the 2009...\n",
              "29313  Touristic cities will suffer from COVID-19 emergency because of its economic impact on their communities. The first emergency phases involved a wide closure of such areas to support \"social distancing\" measures (i.e. travels limitation; lockdown of (over)crowd-prone activities). In the second phase, individual's risk-mitigation strategies (facial masks) could be properly linked to \"social distancing\" to ensure re-opening touristic cities to visitors. Simulation tools could support the effectiveness evaluation of risk-mitigation measures to look for an economic and social optimum for activi...  The smart adaptation of cities against different risks is one of the key challenges for their sustainability and the resilience of the hosted communities (C. Ribeiro and Pena Jardim Gonçalves, 2019) . Urban areas involved by tourists' flows represent a particular application context for such resilience issues, because of the complexity between economic, social (including relationships between tourists' and residents' needs) and organizational tasks, especially in those scenarios in which seasonal tourism is a training element for the community (Feleki et al., 2018; Qie and Rong, 2016; Stan...\n",
              "12609  Background. Effective influenza surveillance requires new methods capable of rapid and inexpensive genomic analysis of evolving viral species for pandemic preparedness, to understand the evolution of circulating viral species, and for vaccine strain selection. We have developed one such approach based on previously described broad-range reverse transcription PCR/ electrospray ionization mass spectrometry (RT-PCR/ESI-MS) technology. Methods and Principal Findings. Analysis of base compositions of RT-PCR amplicons from influenza core gene segments (PB1, PB2, PA, M, NS, NP) are used to provid...  Influenza viruses cause serious global economic and public health burdens. Annual influenza epidemics resulted in more than 30,000 deaths a year in the United States during 1990-1999  . Periodic pandemics result in significantly higher death tolls. Emergence of new influenza A virus strains can be caused by ''antigenic shift,'' resulting from reassortment of gene segments, including H and/or N types  , ''antigenic drift'' resulting from the continuing accumulation of mutations in the H and N genes  , or a pathogenic virus jumping species and acquiring the ability to infect and be transmitt...\n",
              "17432  Memory CD8 T cells can provide protection from re-infection by respiratory viruses such as influenza and SARS. However, the relative contribution of memory CD8 T cells in providing protection against respiratory syncytial virus (RSV) infection is currently unclear. To address this knowledge gap, we utilized a prime-boost immunization approach to induce robust memory CD8 T cell responses in the absence of RSV-specific CD4 T cells and antibodies. Unexpectedly, RSV infection of mice with pre-existing CD8 T cell memory led to exacerbated weight loss, pulmonary disease, and lethal immunopatholo...  a1111111111 a1111111111 a1111111111 a1111111111 a1111111111 \\n\\n Respiratory syncytial virus (RSV) is a major cause of severe disease in young children, the elderly, and immunocompromised populations  . Furthermore, RSV is the leading cause of infant hospitalizations creating an immense healthcare burden for treatment and prevention  . There is currently no licensed vaccine for RSV. During a primary RSV infection, the CD8 T cell response is crucial for mediating viral clearance  . Depletion of CD8 T cells in mice prior to RSV challenge leads to elevated viral loads, but also ameliorates mo..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTfeJJkT-yMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVdorCPVcbzp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55035e97-f0a7-472f-f7d5-1f61c58e472f"
      },
      "source": [
        "body = []\n",
        "for i in tqdm(df_test['Body']):\n",
        "  text = str(i)\n",
        "  new = sent_detector.tokenize(text.strip())\n",
        "  # print(len(new))\n",
        "  if len(new) > 22:\n",
        "    cut_new = new[:25]\n",
        "    hello = ''.join(cut_new)\n",
        "    body.append(hello)\n",
        "    # print(hello)\n",
        "    # print(learn.generate_text(hello))\n",
        "    # print(len(cut_new))\n",
        "  else:\n",
        "    body.append(text)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/4612 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 9/4612 [00:00<00:53, 85.40it/s]\u001b[A\n",
            "  0%|          | 23/4612 [00:00<00:47, 96.50it/s]\u001b[A\n",
            "  1%|          | 30/4612 [00:00<00:54, 84.59it/s]\u001b[A\n",
            "  1%|          | 43/4612 [00:00<00:49, 92.60it/s]\u001b[A\n",
            "  1%|          | 55/4612 [00:00<00:46, 98.17it/s]\u001b[A\n",
            "  2%|▏         | 70/4612 [00:00<00:42, 107.09it/s]\u001b[A\n",
            "  2%|▏         | 85/4612 [00:00<00:39, 114.70it/s]\u001b[A\n",
            "  2%|▏         | 99/4612 [00:00<00:37, 120.14it/s]\u001b[A\n",
            "  2%|▏         | 112/4612 [00:00<00:38, 116.01it/s]\u001b[A\n",
            "  3%|▎         | 125/4612 [00:01<00:38, 117.96it/s]\u001b[A\n",
            "  3%|▎         | 140/4612 [00:01<00:35, 125.23it/s]\u001b[A\n",
            "  3%|▎         | 153/4612 [00:01<00:36, 122.16it/s]\u001b[A\n",
            "  4%|▎         | 166/4612 [00:01<00:36, 121.67it/s]\u001b[A\n",
            "  4%|▍         | 179/4612 [00:01<00:45, 97.80it/s] \u001b[A\n",
            "  4%|▍         | 193/4612 [00:01<00:41, 107.11it/s]\u001b[A\n",
            "  4%|▍         | 205/4612 [00:01<00:42, 103.52it/s]\u001b[A\n",
            "  5%|▍         | 216/4612 [00:01<00:41, 105.19it/s]\u001b[A\n",
            "  5%|▍         | 230/4612 [00:02<00:39, 110.41it/s]\u001b[A\n",
            "  5%|▌         | 242/4612 [00:02<00:38, 112.91it/s]\u001b[A\n",
            "  6%|▌         | 258/4612 [00:02<00:35, 122.09it/s]\u001b[A\n",
            "  6%|▌         | 275/4612 [00:02<00:33, 131.10it/s]\u001b[A\n",
            "  6%|▋         | 289/4612 [00:02<00:33, 127.78it/s]\u001b[A\n",
            "  7%|▋         | 304/4612 [00:02<00:33, 128.99it/s]\u001b[A\n",
            "  7%|▋         | 319/4612 [00:02<00:32, 133.83it/s]\u001b[A\n",
            "  7%|▋         | 333/4612 [00:02<00:33, 128.69it/s]\u001b[A\n",
            "  8%|▊         | 348/4612 [00:02<00:32, 133.17it/s]\u001b[A\n",
            "  8%|▊         | 362/4612 [00:03<00:33, 127.88it/s]\u001b[A\n",
            "  8%|▊         | 376/4612 [00:03<00:32, 128.61it/s]\u001b[A\n",
            "  8%|▊         | 389/4612 [00:03<00:34, 123.01it/s]\u001b[A\n",
            "  9%|▊         | 402/4612 [00:03<00:40, 104.94it/s]\u001b[A\n",
            "  9%|▉         | 416/4612 [00:03<00:38, 110.21it/s]\u001b[A\n",
            "  9%|▉         | 428/4612 [00:03<00:53, 77.84it/s] \u001b[A\n",
            "  9%|▉         | 438/4612 [00:03<00:52, 79.75it/s]\u001b[A\n",
            " 10%|▉         | 450/4612 [00:04<00:47, 88.06it/s]\u001b[A\n",
            " 10%|█         | 464/4612 [00:04<00:42, 96.69it/s]\u001b[A\n",
            " 10%|█         | 477/4612 [00:04<00:39, 103.94it/s]\u001b[A\n",
            " 11%|█         | 494/4612 [00:04<00:35, 115.68it/s]\u001b[A\n",
            " 11%|█         | 507/4612 [00:04<00:51, 79.37it/s] \u001b[A\n",
            " 11%|█▏        | 526/4612 [00:04<00:43, 94.72it/s]\u001b[A\n",
            " 12%|█▏        | 539/4612 [00:04<00:42, 96.40it/s]\u001b[A\n",
            " 12%|█▏        | 554/4612 [00:04<00:38, 105.43it/s]\u001b[A\n",
            " 12%|█▏        | 567/4612 [00:05<00:37, 108.98it/s]\u001b[A\n",
            " 13%|█▎        | 580/4612 [00:05<00:50, 80.48it/s] \u001b[A\n",
            " 13%|█▎        | 593/4612 [00:05<00:44, 90.38it/s]\u001b[A\n",
            " 13%|█▎        | 607/4612 [00:05<00:39, 100.20it/s]\u001b[A\n",
            " 14%|█▎        | 623/4612 [00:05<00:35, 111.99it/s]\u001b[A\n",
            " 14%|█▍        | 636/4612 [00:05<00:34, 116.10it/s]\u001b[A\n",
            " 14%|█▍        | 649/4612 [00:05<00:35, 112.37it/s]\u001b[A\n",
            " 14%|█▍        | 663/4612 [00:05<00:33, 117.54it/s]\u001b[A\n",
            " 15%|█▍        | 676/4612 [00:06<00:36, 107.10it/s]\u001b[A\n",
            " 15%|█▌        | 693/4612 [00:06<00:32, 118.89it/s]\u001b[A\n",
            " 15%|█▌        | 706/4612 [00:06<00:37, 103.25it/s]\u001b[A\n",
            " 16%|█▌        | 718/4612 [00:06<00:36, 106.48it/s]\u001b[A\n",
            " 16%|█▌        | 732/4612 [00:06<00:34, 113.07it/s]\u001b[A\n",
            " 16%|█▌        | 744/4612 [00:06<00:34, 112.65it/s]\u001b[A\n",
            " 16%|█▋        | 757/4612 [00:06<00:32, 117.18it/s]\u001b[A\n",
            " 17%|█▋        | 770/4612 [00:06<00:32, 119.89it/s]\u001b[A\n",
            " 17%|█▋        | 785/4612 [00:07<00:30, 126.84it/s]\u001b[A\n",
            " 17%|█▋        | 798/4612 [00:07<00:30, 126.18it/s]\u001b[A\n",
            " 18%|█▊        | 811/4612 [00:07<00:30, 125.12it/s]\u001b[A\n",
            " 18%|█▊        | 824/4612 [00:07<00:56, 67.61it/s] \u001b[A\n",
            " 18%|█▊        | 834/4612 [00:07<00:50, 74.53it/s]\u001b[A\n",
            " 18%|█▊        | 849/4612 [00:07<00:43, 87.00it/s]\u001b[A\n",
            " 19%|█▊        | 863/4612 [00:07<00:41, 91.03it/s]\u001b[A\n",
            " 19%|█▉        | 876/4612 [00:08<00:38, 98.25it/s]\u001b[A\n",
            " 19%|█▉        | 893/4612 [00:08<00:33, 112.46it/s]\u001b[A\n",
            " 20%|█▉        | 906/4612 [00:08<00:31, 117.19it/s]\u001b[A\n",
            " 20%|██        | 924/4612 [00:08<00:28, 130.66it/s]\u001b[A\n",
            " 20%|██        | 939/4612 [00:08<00:28, 126.89it/s]\u001b[A\n",
            " 21%|██        | 953/4612 [00:08<00:30, 120.04it/s]\u001b[A\n",
            " 21%|██        | 966/4612 [00:08<00:32, 110.87it/s]\u001b[A\n",
            " 21%|██        | 979/4612 [00:08<00:32, 110.24it/s]\u001b[A\n",
            " 21%|██▏       | 991/4612 [00:09<00:33, 106.75it/s]\u001b[A\n",
            " 22%|██▏       | 1003/4612 [00:09<00:33, 106.36it/s]\u001b[A\n",
            " 22%|██▏       | 1019/4612 [00:09<00:30, 116.55it/s]\u001b[A\n",
            " 22%|██▏       | 1033/4612 [00:09<00:29, 121.64it/s]\u001b[A\n",
            " 23%|██▎       | 1046/4612 [00:09<00:29, 121.74it/s]\u001b[A\n",
            " 23%|██▎       | 1060/4612 [00:09<00:28, 125.34it/s]\u001b[A\n",
            " 23%|██▎       | 1073/4612 [00:09<00:28, 123.59it/s]\u001b[A\n",
            " 24%|██▎       | 1086/4612 [00:09<00:28, 121.62it/s]\u001b[A\n",
            " 24%|██▍       | 1099/4612 [00:09<00:29, 120.30it/s]\u001b[A\n",
            " 24%|██▍       | 1113/4612 [00:09<00:28, 124.75it/s]\u001b[A\n",
            " 24%|██▍       | 1126/4612 [00:10<00:27, 125.25it/s]\u001b[A\n",
            " 25%|██▍       | 1139/4612 [00:10<00:27, 125.01it/s]\u001b[A\n",
            " 25%|██▍       | 1152/4612 [00:10<00:27, 125.73it/s]\u001b[A\n",
            " 25%|██▌       | 1165/4612 [00:10<00:31, 109.72it/s]\u001b[A\n",
            " 26%|██▌       | 1177/4612 [00:10<00:30, 112.05it/s]\u001b[A\n",
            " 26%|██▌       | 1190/4612 [00:10<00:29, 115.23it/s]\u001b[A\n",
            " 26%|██▌       | 1202/4612 [00:10<00:48, 70.74it/s] \u001b[A\n",
            " 26%|██▋       | 1218/4612 [00:11<00:40, 84.84it/s]\u001b[A\n",
            " 27%|██▋       | 1230/4612 [00:11<01:13, 46.19it/s]\u001b[A\n",
            " 27%|██▋       | 1243/4612 [00:11<01:00, 55.89it/s]\u001b[A\n",
            " 27%|██▋       | 1258/4612 [00:11<00:49, 68.26it/s]\u001b[A\n",
            " 28%|██▊       | 1269/4612 [00:11<00:48, 68.31it/s]\u001b[A\n",
            " 28%|██▊       | 1282/4612 [00:12<00:41, 79.33it/s]\u001b[A\n",
            " 28%|██▊       | 1293/4612 [00:12<00:45, 72.89it/s]\u001b[A\n",
            " 28%|██▊       | 1303/4612 [00:12<00:48, 67.89it/s]\u001b[A\n",
            " 29%|██▊       | 1315/4612 [00:12<00:42, 77.84it/s]\u001b[A\n",
            " 29%|██▉       | 1330/4612 [00:12<00:36, 89.37it/s]\u001b[A\n",
            " 29%|██▉       | 1342/4612 [00:12<00:34, 95.80it/s]\u001b[A\n",
            " 29%|██▉       | 1354/4612 [00:12<00:32, 101.23it/s]\u001b[A\n",
            " 30%|██▉       | 1366/4612 [00:12<00:32, 99.96it/s] \u001b[A\n",
            " 30%|██▉       | 1379/4612 [00:13<00:30, 105.46it/s]\u001b[A\n",
            " 30%|███       | 1391/4612 [00:13<00:32, 98.65it/s] \u001b[A\n",
            " 30%|███       | 1404/4612 [00:13<00:30, 105.57it/s]\u001b[A\n",
            " 31%|███       | 1416/4612 [00:13<00:30, 106.40it/s]\u001b[A\n",
            " 31%|███       | 1427/4612 [00:13<00:46, 67.95it/s] \u001b[A\n",
            " 31%|███       | 1440/4612 [00:13<00:40, 78.91it/s]\u001b[A\n",
            " 32%|███▏      | 1456/4612 [00:13<00:34, 91.77it/s]\u001b[A\n",
            " 32%|███▏      | 1468/4612 [00:14<00:32, 97.44it/s]\u001b[A\n",
            " 32%|███▏      | 1482/4612 [00:14<00:29, 106.69it/s]\u001b[A\n",
            " 32%|███▏      | 1495/4612 [00:14<00:28, 108.51it/s]\u001b[A\n",
            " 33%|███▎      | 1508/4612 [00:14<00:27, 113.53it/s]\u001b[A\n",
            " 33%|███▎      | 1527/4612 [00:14<00:24, 126.88it/s]\u001b[A\n",
            " 33%|███▎      | 1541/4612 [00:14<00:25, 122.23it/s]\u001b[A\n",
            " 34%|███▎      | 1554/4612 [00:14<00:25, 121.63it/s]\u001b[A\n",
            " 34%|███▍      | 1571/4612 [00:14<00:22, 132.23it/s]\u001b[A\n",
            " 34%|███▍      | 1585/4612 [00:14<00:22, 132.24it/s]\u001b[A\n",
            " 35%|███▍      | 1599/4612 [00:15<00:32, 92.14it/s] \u001b[A\n",
            " 35%|███▍      | 1611/4612 [00:15<00:32, 93.76it/s]\u001b[A\n",
            " 35%|███▌      | 1625/4612 [00:15<00:28, 103.43it/s]\u001b[A\n",
            " 36%|███▌      | 1639/4612 [00:15<00:26, 110.76it/s]\u001b[A\n",
            " 36%|███▌      | 1653/4612 [00:15<00:25, 117.19it/s]\u001b[A\n",
            " 36%|███▌      | 1666/4612 [00:15<00:26, 113.01it/s]\u001b[A\n",
            " 36%|███▋      | 1678/4612 [00:15<00:27, 104.91it/s]\u001b[A\n",
            " 37%|███▋      | 1690/4612 [00:16<00:35, 82.51it/s] \u001b[A\n",
            " 37%|███▋      | 1704/4612 [00:16<00:30, 94.09it/s]\u001b[A\n",
            " 37%|███▋      | 1715/4612 [00:16<00:31, 92.47it/s]\u001b[A\n",
            " 38%|███▊      | 1731/4612 [00:16<00:27, 104.86it/s]\u001b[A\n",
            " 38%|███▊      | 1743/4612 [00:16<00:27, 105.53it/s]\u001b[A\n",
            " 38%|███▊      | 1755/4612 [00:16<00:27, 102.95it/s]\u001b[A\n",
            " 38%|███▊      | 1767/4612 [00:16<00:26, 105.72it/s]\u001b[A\n",
            " 39%|███▊      | 1779/4612 [00:16<00:26, 106.69it/s]\u001b[A\n",
            " 39%|███▉      | 1791/4612 [00:17<00:38, 73.80it/s] \u001b[A\n",
            " 39%|███▉      | 1800/4612 [00:17<00:36, 77.61it/s]\u001b[A\n",
            " 39%|███▉      | 1813/4612 [00:17<00:31, 87.47it/s]\u001b[A\n",
            " 40%|███▉      | 1823/4612 [00:17<00:30, 90.88it/s]\u001b[A\n",
            " 40%|███▉      | 1835/4612 [00:17<00:28, 96.88it/s]\u001b[A\n",
            " 40%|████      | 1855/4612 [00:17<00:24, 113.84it/s]\u001b[A\n",
            " 41%|████      | 1869/4612 [00:17<00:22, 120.01it/s]\u001b[A\n",
            " 41%|████      | 1883/4612 [00:17<00:24, 112.69it/s]\u001b[A\n",
            " 41%|████      | 1896/4612 [00:18<00:24, 110.51it/s]\u001b[A\n",
            " 41%|████▏     | 1908/4612 [00:18<00:24, 108.38it/s]\u001b[A\n",
            " 42%|████▏     | 1920/4612 [00:18<00:38, 69.74it/s] \u001b[A\n",
            " 42%|████▏     | 1934/4612 [00:18<00:33, 80.59it/s]\u001b[A\n",
            " 42%|████▏     | 1948/4612 [00:18<00:29, 89.51it/s]\u001b[A\n",
            " 42%|████▏     | 1960/4612 [00:18<00:27, 96.38it/s]\u001b[A\n",
            " 43%|████▎     | 1972/4612 [00:19<00:43, 60.40it/s]\u001b[A\n",
            " 43%|████▎     | 1989/4612 [00:19<00:35, 74.04it/s]\u001b[A\n",
            " 43%|████▎     | 2002/4612 [00:19<00:31, 84.01it/s]\u001b[A\n",
            " 44%|████▎     | 2015/4612 [00:19<00:27, 93.45it/s]\u001b[A\n",
            " 44%|████▍     | 2030/4612 [00:19<00:25, 103.22it/s]\u001b[A\n",
            " 44%|████▍     | 2046/4612 [00:19<00:22, 113.93it/s]\u001b[A\n",
            " 45%|████▍     | 2060/4612 [00:19<00:21, 119.98it/s]\u001b[A\n",
            " 45%|████▍     | 2074/4612 [00:19<00:21, 118.93it/s]\u001b[A\n",
            " 45%|████▌     | 2088/4612 [00:20<00:20, 122.74it/s]\u001b[A\n",
            " 46%|████▌     | 2101/4612 [00:20<00:20, 122.88it/s]\u001b[A\n",
            " 46%|████▌     | 2114/4612 [00:20<00:22, 113.36it/s]\u001b[A\n",
            " 46%|████▌     | 2126/4612 [00:20<00:22, 110.91it/s]\u001b[A\n",
            " 46%|████▋     | 2138/4612 [00:20<00:22, 111.56it/s]\u001b[A\n",
            " 47%|████▋     | 2152/4612 [00:20<00:21, 116.78it/s]\u001b[A\n",
            " 47%|████▋     | 2166/4612 [00:20<00:19, 122.87it/s]\u001b[A\n",
            " 47%|████▋     | 2179/4612 [00:20<00:20, 117.97it/s]\u001b[A\n",
            " 48%|████▊     | 2192/4612 [00:20<00:20, 119.58it/s]\u001b[A\n",
            " 48%|████▊     | 2205/4612 [00:21<00:19, 120.36it/s]\u001b[A\n",
            " 48%|████▊     | 2218/4612 [00:21<00:20, 117.46it/s]\u001b[A\n",
            " 48%|████▊     | 2230/4612 [00:21<00:27, 86.06it/s] \u001b[A\n",
            " 49%|████▊     | 2241/4612 [00:21<00:27, 87.38it/s]\u001b[A\n",
            " 49%|████▉     | 2256/4612 [00:21<00:24, 98.02it/s]\u001b[A\n",
            " 49%|████▉     | 2268/4612 [00:21<00:22, 103.17it/s]\u001b[A\n",
            " 49%|████▉     | 2280/4612 [00:21<00:23, 99.52it/s] \u001b[A\n",
            " 50%|████▉     | 2295/4612 [00:21<00:21, 110.04it/s]\u001b[A\n",
            " 50%|█████     | 2312/4612 [00:22<00:18, 121.89it/s]\u001b[A\n",
            " 50%|█████     | 2327/4612 [00:22<00:17, 128.44it/s]\u001b[A\n",
            " 51%|█████     | 2341/4612 [00:22<00:17, 129.20it/s]\u001b[A\n",
            " 51%|█████     | 2355/4612 [00:22<00:21, 107.01it/s]\u001b[A\n",
            " 51%|█████▏    | 2369/4612 [00:22<00:20, 110.11it/s]\u001b[A\n",
            " 52%|█████▏    | 2381/4612 [00:22<00:21, 105.80it/s]\u001b[A\n",
            " 52%|█████▏    | 2398/4612 [00:22<00:18, 118.64it/s]\u001b[A\n",
            " 52%|█████▏    | 2414/4612 [00:22<00:17, 126.02it/s]\u001b[A\n",
            " 53%|█████▎    | 2428/4612 [00:23<00:17, 128.24it/s]\u001b[A\n",
            " 53%|█████▎    | 2442/4612 [00:23<00:16, 129.50it/s]\u001b[A\n",
            " 53%|█████▎    | 2456/4612 [00:23<00:17, 122.59it/s]\u001b[A\n",
            " 54%|█████▎    | 2471/4612 [00:23<00:16, 126.08it/s]\u001b[A\n",
            " 54%|█████▍    | 2486/4612 [00:23<00:16, 128.47it/s]\u001b[A\n",
            " 54%|█████▍    | 2501/4612 [00:23<00:15, 134.07it/s]\u001b[A\n",
            " 55%|█████▍    | 2517/4612 [00:23<00:14, 140.84it/s]\u001b[A\n",
            " 55%|█████▍    | 2533/4612 [00:23<00:14, 145.24it/s]\u001b[A\n",
            " 55%|█████▌    | 2548/4612 [00:23<00:14, 141.31it/s]\u001b[A\n",
            " 56%|█████▌    | 2563/4612 [00:24<00:15, 130.28it/s]\u001b[A\n",
            " 56%|█████▌    | 2578/4612 [00:24<00:15, 134.25it/s]\u001b[A\n",
            " 56%|█████▌    | 2592/4612 [00:24<00:14, 135.72it/s]\u001b[A\n",
            " 57%|█████▋    | 2606/4612 [00:24<00:16, 118.92it/s]\u001b[A\n",
            " 57%|█████▋    | 2621/4612 [00:24<00:15, 125.36it/s]\u001b[A\n",
            " 57%|█████▋    | 2635/4612 [00:24<00:15, 126.94it/s]\u001b[A\n",
            " 57%|█████▋    | 2649/4612 [00:24<00:16, 116.57it/s]\u001b[A\n",
            " 58%|█████▊    | 2662/4612 [00:24<00:16, 118.75it/s]\u001b[A\n",
            " 58%|█████▊    | 2677/4612 [00:24<00:15, 124.58it/s]\u001b[A\n",
            " 58%|█████▊    | 2691/4612 [00:25<00:15, 127.03it/s]\u001b[A\n",
            " 59%|█████▊    | 2704/4612 [00:25<00:16, 116.62it/s]\u001b[A\n",
            " 59%|█████▉    | 2716/4612 [00:25<00:16, 115.77it/s]\u001b[A\n",
            " 59%|█████▉    | 2730/4612 [00:25<00:15, 121.30it/s]\u001b[A\n",
            " 59%|█████▉    | 2743/4612 [00:25<00:15, 120.06it/s]\u001b[A\n",
            " 60%|█████▉    | 2759/4612 [00:25<00:14, 129.16it/s]\u001b[A\n",
            " 60%|██████    | 2773/4612 [00:25<00:14, 125.65it/s]\u001b[A\n",
            " 60%|██████    | 2788/4612 [00:25<00:14, 127.16it/s]\u001b[A\n",
            " 61%|██████    | 2801/4612 [00:25<00:16, 112.05it/s]\u001b[A\n",
            " 61%|██████    | 2813/4612 [00:26<00:16, 111.95it/s]\u001b[A\n",
            " 61%|██████▏   | 2826/4612 [00:26<00:15, 115.85it/s]\u001b[A\n",
            " 62%|██████▏   | 2841/4612 [00:26<00:14, 121.85it/s]\u001b[A\n",
            " 62%|██████▏   | 2856/4612 [00:26<00:13, 127.66it/s]\u001b[A\n",
            " 62%|██████▏   | 2870/4612 [00:26<00:13, 126.12it/s]\u001b[A\n",
            " 63%|██████▎   | 2883/4612 [00:26<00:14, 122.45it/s]\u001b[A\n",
            " 63%|██████▎   | 2896/4612 [00:26<00:16, 104.91it/s]\u001b[A\n",
            " 63%|██████▎   | 2908/4612 [00:26<00:17, 94.91it/s] \u001b[A\n",
            " 63%|██████▎   | 2920/4612 [00:27<00:17, 98.86it/s]\u001b[A\n",
            " 64%|██████▎   | 2932/4612 [00:27<00:33, 49.57it/s]\u001b[A\n",
            " 64%|██████▎   | 2940/4612 [00:27<00:35, 47.08it/s]\u001b[A\n",
            " 64%|██████▍   | 2954/4612 [00:27<00:28, 58.30it/s]\u001b[A\n",
            " 64%|██████▍   | 2967/4612 [00:27<00:23, 69.53it/s]\u001b[A\n",
            " 65%|██████▍   | 2983/4612 [00:28<00:19, 83.10it/s]\u001b[A\n",
            " 65%|██████▍   | 2996/4612 [00:28<00:17, 92.61it/s]\u001b[A\n",
            " 65%|██████▌   | 3013/4612 [00:28<00:14, 106.85it/s]\u001b[A\n",
            " 66%|██████▌   | 3027/4612 [00:28<00:13, 113.29it/s]\u001b[A\n",
            " 66%|██████▌   | 3043/4612 [00:28<00:12, 122.61it/s]\u001b[A\n",
            " 66%|██████▋   | 3057/4612 [00:28<00:12, 124.44it/s]\u001b[A\n",
            " 67%|██████▋   | 3071/4612 [00:28<00:12, 128.25it/s]\u001b[A\n",
            " 67%|██████▋   | 3085/4612 [00:28<00:13, 112.70it/s]\u001b[A\n",
            " 67%|██████▋   | 3099/4612 [00:28<00:12, 117.94it/s]\u001b[A\n",
            " 67%|██████▋   | 3112/4612 [00:29<00:13, 113.54it/s]\u001b[A\n",
            " 68%|██████▊   | 3125/4612 [00:29<00:12, 117.40it/s]\u001b[A\n",
            " 68%|██████▊   | 3138/4612 [00:29<00:13, 111.97it/s]\u001b[A\n",
            " 68%|██████▊   | 3152/4612 [00:29<00:12, 117.01it/s]\u001b[A\n",
            " 69%|██████▊   | 3167/4612 [00:29<00:11, 125.17it/s]\u001b[A\n",
            " 69%|██████▉   | 3181/4612 [00:29<00:11, 124.04it/s]\u001b[A\n",
            " 69%|██████▉   | 3194/4612 [00:29<00:11, 118.43it/s]\u001b[A\n",
            " 70%|██████▉   | 3211/4612 [00:29<00:10, 127.84it/s]\u001b[A\n",
            " 70%|██████▉   | 3226/4612 [00:29<00:10, 129.78it/s]\u001b[A\n",
            " 70%|███████   | 3240/4612 [00:30<00:11, 120.95it/s]\u001b[A\n",
            " 71%|███████   | 3256/4612 [00:30<00:10, 129.53it/s]\u001b[A\n",
            " 71%|███████   | 3270/4612 [00:30<00:10, 128.01it/s]\u001b[A\n",
            " 71%|███████   | 3285/4612 [00:30<00:09, 133.83it/s]\u001b[A\n",
            " 72%|███████▏  | 3299/4612 [00:30<00:09, 135.14it/s]\u001b[A\n",
            " 72%|███████▏  | 3317/4612 [00:30<00:08, 145.53it/s]\u001b[A\n",
            " 72%|███████▏  | 3332/4612 [00:30<00:09, 141.10it/s]\u001b[A\n",
            " 73%|███████▎  | 3347/4612 [00:30<00:09, 138.31it/s]\u001b[A\n",
            " 73%|███████▎  | 3362/4612 [00:30<00:08, 141.52it/s]\u001b[A\n",
            " 73%|███████▎  | 3377/4612 [00:31<00:09, 125.30it/s]\u001b[A\n",
            " 74%|███████▎  | 3391/4612 [00:31<00:09, 129.18it/s]\u001b[A\n",
            " 74%|███████▍  | 3405/4612 [00:31<00:09, 130.94it/s]\u001b[A\n",
            " 74%|███████▍  | 3419/4612 [00:31<00:09, 129.66it/s]\u001b[A\n",
            " 74%|███████▍  | 3433/4612 [00:31<00:10, 115.14it/s]\u001b[A\n",
            " 75%|███████▍  | 3447/4612 [00:31<00:09, 121.28it/s]\u001b[A\n",
            " 75%|███████▌  | 3464/4612 [00:31<00:08, 131.10it/s]\u001b[A\n",
            " 75%|███████▌  | 3478/4612 [00:31<00:08, 132.98it/s]\u001b[A\n",
            " 76%|███████▌  | 3492/4612 [00:32<00:08, 128.82it/s]\u001b[A\n",
            " 76%|███████▌  | 3506/4612 [00:32<00:09, 114.82it/s]\u001b[A\n",
            " 76%|███████▋  | 3521/4612 [00:32<00:08, 122.92it/s]\u001b[A\n",
            " 77%|███████▋  | 3534/4612 [00:32<00:08, 124.56it/s]\u001b[A\n",
            " 77%|███████▋  | 3549/4612 [00:32<00:08, 128.67it/s]\u001b[A\n",
            " 77%|███████▋  | 3563/4612 [00:32<00:08, 120.46it/s]\u001b[A\n",
            " 78%|███████▊  | 3578/4612 [00:32<00:08, 125.96it/s]\u001b[A\n",
            " 78%|███████▊  | 3591/4612 [00:32<00:08, 124.82it/s]\u001b[A\n",
            " 78%|███████▊  | 3607/4612 [00:32<00:07, 131.72it/s]\u001b[A\n",
            " 79%|███████▊  | 3621/4612 [00:33<00:07, 128.85it/s]\u001b[A\n",
            " 79%|███████▉  | 3635/4612 [00:33<00:10, 97.58it/s] \u001b[A\n",
            " 79%|███████▉  | 3649/4612 [00:33<00:09, 106.48it/s]\u001b[A\n",
            " 79%|███████▉  | 3663/4612 [00:33<00:08, 114.45it/s]\u001b[A\n",
            " 80%|███████▉  | 3676/4612 [00:33<00:15, 61.66it/s] \u001b[A\n",
            " 80%|███████▉  | 3686/4612 [00:34<00:13, 69.63it/s]\u001b[A\n",
            " 80%|████████  | 3697/4612 [00:34<00:11, 77.86it/s]\u001b[A\n",
            " 80%|████████  | 3711/4612 [00:34<00:10, 88.19it/s]\u001b[A\n",
            " 81%|████████  | 3723/4612 [00:34<00:09, 95.31it/s]\u001b[A\n",
            " 81%|████████  | 3737/4612 [00:34<00:08, 104.88it/s]\u001b[A\n",
            " 81%|████████▏ | 3752/4612 [00:34<00:07, 113.19it/s]\u001b[A\n",
            " 82%|████████▏ | 3768/4612 [00:34<00:06, 123.09it/s]\u001b[A\n",
            " 82%|████████▏ | 3782/4612 [00:34<00:06, 124.75it/s]\u001b[A\n",
            " 82%|████████▏ | 3796/4612 [00:34<00:06, 118.42it/s]\u001b[A\n",
            " 83%|████████▎ | 3809/4612 [00:35<00:10, 74.39it/s] \u001b[A\n",
            " 83%|████████▎ | 3823/4612 [00:35<00:09, 85.56it/s]\u001b[A\n",
            " 83%|████████▎ | 3840/4612 [00:35<00:07, 100.25it/s]\u001b[A\n",
            " 84%|████████▎ | 3853/4612 [00:35<00:07, 106.85it/s]\u001b[A\n",
            " 84%|████████▍ | 3867/4612 [00:36<00:12, 58.31it/s] \u001b[A\n",
            " 84%|████████▍ | 3882/4612 [00:36<00:10, 71.31it/s]\u001b[A\n",
            " 85%|████████▍ | 3902/4612 [00:36<00:08, 88.02it/s]\u001b[A\n",
            " 85%|████████▍ | 3916/4612 [00:36<00:07, 94.25it/s]\u001b[A\n",
            " 85%|████████▌ | 3929/4612 [00:36<00:14, 47.53it/s]\u001b[A\n",
            " 86%|████████▌ | 3946/4612 [00:37<00:11, 60.23it/s]\u001b[A\n",
            " 86%|████████▌ | 3958/4612 [00:37<00:11, 59.44it/s]\u001b[A\n",
            " 86%|████████▌ | 3973/4612 [00:37<00:10, 59.58it/s]\u001b[A\n",
            " 86%|████████▋ | 3986/4612 [00:37<00:08, 70.46it/s]\u001b[A\n",
            " 87%|████████▋ | 3996/4612 [00:37<00:08, 75.19it/s]\u001b[A\n",
            " 87%|████████▋ | 4011/4612 [00:37<00:06, 87.23it/s]\u001b[A\n",
            " 87%|████████▋ | 4024/4612 [00:37<00:06, 94.99it/s]\u001b[A\n",
            " 88%|████████▊ | 4036/4612 [00:38<00:06, 95.25it/s]\u001b[A\n",
            " 88%|████████▊ | 4048/4612 [00:38<00:05, 100.01it/s]\u001b[A\n",
            " 88%|████████▊ | 4061/4612 [00:38<00:05, 107.08it/s]\u001b[A\n",
            " 88%|████████▊ | 4074/4612 [00:38<00:04, 109.08it/s]\u001b[A\n",
            " 89%|████████▊ | 4086/4612 [00:38<00:09, 54.13it/s] \u001b[A\n",
            " 89%|████████▉ | 4100/4612 [00:38<00:07, 65.83it/s]\u001b[A\n",
            " 89%|████████▉ | 4112/4612 [00:39<00:06, 75.44it/s]\u001b[A\n",
            " 89%|████████▉ | 4125/4612 [00:39<00:05, 85.07it/s]\u001b[A\n",
            " 90%|████████▉ | 4137/4612 [00:39<00:05, 91.71it/s]\u001b[A\n",
            " 90%|████████▉ | 4150/4612 [00:39<00:04, 99.66it/s]\u001b[A\n",
            " 90%|█████████ | 4163/4612 [00:39<00:04, 106.48it/s]\u001b[A\n",
            " 91%|█████████ | 4175/4612 [00:39<00:04, 107.71it/s]\u001b[A\n",
            " 91%|█████████ | 4188/4612 [00:39<00:03, 113.23it/s]\u001b[A\n",
            " 91%|█████████ | 4205/4612 [00:39<00:03, 124.64it/s]\u001b[A\n",
            " 92%|█████████▏| 4220/4612 [00:39<00:03, 130.33it/s]\u001b[A\n",
            " 92%|█████████▏| 4235/4612 [00:40<00:02, 132.25it/s]\u001b[A\n",
            " 92%|█████████▏| 4251/4612 [00:40<00:02, 138.74it/s]\u001b[A\n",
            " 92%|█████████▏| 4266/4612 [00:40<00:02, 126.87it/s]\u001b[A\n",
            " 93%|█████████▎| 4280/4612 [00:40<00:02, 128.90it/s]\u001b[A\n",
            " 93%|█████████▎| 4295/4612 [00:40<00:02, 132.96it/s]\u001b[A\n",
            " 93%|█████████▎| 4309/4612 [00:40<00:02, 133.72it/s]\u001b[A\n",
            " 94%|█████████▎| 4323/4612 [00:40<00:02, 124.08it/s]\u001b[A\n",
            " 94%|█████████▍| 4336/4612 [00:40<00:02, 120.98it/s]\u001b[A\n",
            " 94%|█████████▍| 4349/4612 [00:40<00:02, 110.40it/s]\u001b[A\n",
            " 95%|█████████▍| 4363/4612 [00:41<00:02, 115.05it/s]\u001b[A\n",
            " 95%|█████████▍| 4375/4612 [00:41<00:02, 115.82it/s]\u001b[A\n",
            " 95%|█████████▌| 4389/4612 [00:41<00:01, 120.32it/s]\u001b[A\n",
            " 95%|█████████▌| 4402/4612 [00:41<00:01, 121.97it/s]\u001b[A\n",
            " 96%|█████████▌| 4416/4612 [00:41<00:01, 125.84it/s]\u001b[A\n",
            " 96%|█████████▌| 4429/4612 [00:41<00:01, 127.04it/s]\u001b[A\n",
            " 96%|█████████▋| 4442/4612 [00:41<00:01, 126.89it/s]\u001b[A\n",
            " 97%|█████████▋| 4456/4612 [00:41<00:01, 129.54it/s]\u001b[A\n",
            " 97%|█████████▋| 4470/4612 [00:41<00:01, 109.91it/s]\u001b[A\n",
            " 97%|█████████▋| 4483/4612 [00:42<00:01, 113.48it/s]\u001b[A\n",
            " 97%|█████████▋| 4495/4612 [00:42<00:01, 107.46it/s]\u001b[A\n",
            " 98%|█████████▊| 4510/4612 [00:42<00:00, 115.42it/s]\u001b[A\n",
            " 98%|█████████▊| 4524/4612 [00:42<00:00, 119.99it/s]\u001b[A\n",
            " 98%|█████████▊| 4537/4612 [00:42<00:00, 109.78it/s]\u001b[A\n",
            " 99%|█████████▊| 4549/4612 [00:42<00:00, 96.13it/s] \u001b[A\n",
            " 99%|█████████▉| 4563/4612 [00:42<00:00, 105.79it/s]\u001b[A\n",
            " 99%|█████████▉| 4575/4612 [00:42<00:00, 89.87it/s] \u001b[A\n",
            " 99%|█████████▉| 4585/4612 [00:43<00:00, 90.26it/s]\u001b[A\n",
            "100%|█████████▉| 4598/4612 [00:43<00:00, 98.78it/s]\u001b[A\n",
            "100%|██████████| 4612/4612 [00:43<00:00, 106.37it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkaWWcUdcf7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "b8ef821d-97d1-4dfb-a844-fe78ba9b0012"
      },
      "source": [
        "pred = []\n",
        "for i in tqdm(body[:2000]):\n",
        "  pred.append(learn.generate_text(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/2000 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "  0%|          | 1/2000 [00:58<32:29:15, 58.51s/it]\u001b[A\u001b[A\n",
            "\n",
            "  0%|          | 2/2000 [01:50<31:23:20, 56.56s/it]\u001b[A\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (1347 > 1024). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-7c4c171b22e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/blurr/modeling/text_generation.py\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(self, inp, max_length, min_length, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mgen_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     outputs = [ hf_tokenizer.decode(txt, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, num_return_sequences, attention_mask, decoder_start_token_id, use_cache, **model_specific_kwargs)\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m             \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0;31m# Expand input ids if num_beams > 1 or num_return_sequences > 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0membed_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_positions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0membed_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, use_cache)\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0mpositions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_position_ids_from_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1722\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvIexOBNfZyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = {'full':df_test['Body'], 'short':body, 'abstract':df_test['Abstract']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxwC8UfTf8V6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(data=d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9fxwjDIgWJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(df,'/content/drive/My Drive/semester 11/cse465/Project/dataset/inference.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBNU8XJYidNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0a662ebe-f0a1-4499-dd92-0896a39ee462"
      },
      "source": [
        "i = df_test['Body'][:1]\n",
        "i"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14125    Since the severe acute respiratory syndrome (SARS) epidemic of 2003 around the world, many researchers have attempted to determine the natural reservoir of the SARS-associated coronavirus (SARS-CoV). Studies on the possible animal source of SARS-CoV have mainly focused on the Himalyan palm civet (Paguma larvata), though other animals (e.g. the raccoon dog, Nyctereutes procyonoides) have been shown to carry coronaviruses closely related to the SARS-CoV. Of note, these related animal coronaviruses possess a 29 base-pair sequence (position 27,869-27,897) in the 1386-6532/$ -see front matter ©...\n",
              "Name: Body, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR-S68DIk71C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}